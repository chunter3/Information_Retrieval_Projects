{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizing, Inverted Indexes, & Query Search",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhYn3kAflTuPJ8e9yBnwj9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunter3/Information_Retrieval_Projects/blob/master/Tokenizing%2C_Inverted_Indexes%2C_%26_Query_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AbpN2rb1emIp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1 (start)"
      ],
      "metadata": {
        "id": "Bmi6M6nseti4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the \"20newsgroups\" sample dataset\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsGroups_ds = fetch_20newsgroups(subset='all', shuffle='False')\n",
        "newsGroups_ds.data # returns the total number of samples from the 20newsgroups dataset (of which there are 18846)"
      ],
      "metadata": {
        "id": "oovy3C4FeyNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization function (using the regular expression (re) module)\n",
        "\n",
        "def Tokenize(docData):\n",
        "  tokenizedDocs = []                               \n",
        "  for msg in docData:\n",
        "    processMsg = re.sub('[^A-Za-z0-9]+',' ', msg)  # takes a msg from docData and removes all instances of special characters (including punctuation); processes the msg\n",
        "    tokenizedMsg = processMsg.split()              # uses the built-in Python split() method to split the processed msg using whitespace as a delimiter\n",
        "    tokenizedDocs.append(tokenizedMsg)\n",
        "  return tokenizedDocs                             # \"tokenizedDocs\" is a 2D array (an array of arrays)"
      ],
      "metadata": {
        "id": "B5z5o-gMxZbg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tokenize(newsGroups_ds.data)"
      ],
      "metadata": {
        "id": "kiRXdsELARQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1 (end)"
      ],
      "metadata": {
        "id": "5x3z_QdsMGXm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2 (start)"
      ],
      "metadata": {
        "id": "QWvZEbselKe2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverted index function\n",
        "\n",
        "def InvertedIndex(tokenizedDocs):\n",
        "  invertedIndex = {}\n",
        "  docID = 0\n",
        "  for tokenizedDoc in tokenizedDocs:\n",
        "    docID += 1\n",
        "    for token in tokenizedDoc:\n",
        "      if token in invertedIndex and docID not in invertedIndex[token]:\n",
        "        invertedIndex[token].append(docID)\n",
        "      else:\n",
        "        invertedIndex[token] = [docID]\n",
        "  return invertedIndex"
      ],
      "metadata": {
        "id": "DKI1wYZLlNUG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizedDocs = Tokenize(newsGroups_ds.data)\n",
        "invertedIndex = InvertedIndex(tokenizedDocs)\n",
        "invertedIndex"
      ],
      "metadata": {
        "id": "YP9LTIPlwsk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Token count function; determines number of appearances of each token across all documents\n",
        " \n",
        "def TokenCount(tokenizedDocs): \n",
        "  tokenCount = {}\n",
        "  for tokenizedDoc in tokenizedDocs:\n",
        "    for token in tokenizedDoc:\n",
        "      if token in tokenCount:\n",
        "        tokenCount[token] += 1\n",
        "      else:\n",
        "        tokenCount[token] = 1\n",
        "  return sorted(tokenCount.items(), key=lambda x: x[1], reverse=True)  # returns a dictionary sorted by the descending order of the keys' values"
      ],
      "metadata": {
        "id": "BwxtihZMuTx5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TokenCount(tokenizedDocs)"
      ],
      "metadata": {
        "id": "KUNj2L8LshgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2 (end)"
      ],
      "metadata": {
        "id": "ExU37Efr3rZM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3 (start)"
      ],
      "metadata": {
        "id": "2CZsaXhq9jWs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intersect auxilary function (part a of problem 3); returns a list of unique docIDs from the intersection of two list values from the inverted index\n",
        "\n",
        "def Intersect(p1,p2):          # p1 and p2 are the list values of two arbitrary entries from the inverted index in problem 2\n",
        " ans = []  \n",
        " while p1 and p2:\n",
        "   if p1[0] == p2[0]:\n",
        "     ans.append(p1[0])\n",
        "     del p1[0]\n",
        "     del p2[0]\n",
        "   elif p1[0] < p2[0]:\n",
        "     del p1[0]\n",
        "   else:\n",
        "     del p2[0]\n",
        " return ans"
      ],
      "metadata": {
        "id": "abzWHO9KDHbc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's examine a test input to verify the intersect function's correctness. Given the query 'Mamatha' AND 'po4' Intersect() should return [1,334,11486] \n",
        "p1 = invertedIndex['Mamatha']\n",
        "p2 = invertedIndex['po4']"
      ],
      "metadata": {
        "id": "d_4CkT8FvKAG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1"
      ],
      "metadata": {
        "id": "EdCw1BvDw6Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p2"
      ],
      "metadata": {
        "id": "yIYFwTCSw8nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing intersect function\n",
        "actual = Intersect(p1,p2)  \n",
        "assert actual == [1, 334, 11486] "
      ],
      "metadata": {
        "id": "QR_-XhshyPpE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort auxilary function (part b of problem 3); returns a word list that's sorted based on the words' number of postings (according to the inverted index)\n",
        "\n",
        "def Sort(wordLst, index):\n",
        "  unsortedAuxDict = {}       # an unsorted dictionary based on the given word list; used to help sort the word list accordingly\n",
        "  for term in wordLst:\n",
        "    if term not in index:\n",
        "      unsortedAuxDict[term] = 0    # if a word in the word list isn't in the index, then it's treated as having a posting of 0\n",
        "      continue\n",
        "    unsortedAuxDict[term] = len(index[term])\n",
        "  sortedAuxDict = dict(sorted(unsortedAuxDict.items(), key=lambda item: item[1]))\n",
        "  return list(sortedAuxDict.keys())  "
      ],
      "metadata": {
        "id": "hlQywMZM1zZt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's examine a test input to verify the sort function's correctness. Given the word list ['Mamatha', 'The', 'only', 'which'] Sort() should return ['Mamatha', 'only', 'which', 'The']\n",
        "\n",
        "wordLst = ['Mamatha', 'The', 'only', 'which']\n",
        "Sort(wordLst,invertedIndex)"
      ],
      "metadata": {
        "id": "G7tMX7Hy1XzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3 (end)"
      ],
      "metadata": {
        "id": "9LDoRmS7G6Rx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 4 (start)"
      ],
      "metadata": {
        "id": "z1_cSOU2G8lO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizedDocs = Tokenize(newsGroups_ds.data)\n",
        "invertedIndex = InvertedIndex(tokenizedDocs)"
      ],
      "metadata": {
        "id": "zOcXMA_llezV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query search function\n",
        "\n",
        "def QuerySearch(query,index):\n",
        "  ans = []\n",
        "  tokens = query.replace('AND',\"\").split()       # Tokenizing the query\n",
        "  if len(tokens) < 2:                            # If there are less than 2 tokens, then an intersection is impossible\n",
        "    return tokens\n",
        "  for token in tokens:\n",
        "    if token not in index:           # If there are tokens not present in the inverted index, then add them to the index with a value of an empty list\n",
        "      index[token] = []\n",
        "  if len(tokens) == 2:\n",
        "    return Intersect(index[tokens[0]],index[tokens[1]])     # If there are only two tokens, then immediately return their intersection\n",
        "  sortedWordLst = Sort(tokens,index)\n",
        "  p1 = Intersect(index[sortedWordLst[0]],index[sortedWordLst[1]])\n",
        "  del sortedWordLst[:2]\n",
        "  for word in sortedWordLst:\n",
        "    ans = Intersect(p1,index[word])\n",
        "    p1 = ans\n",
        "  return ans"
      ],
      "metadata": {
        "id": "UWzUzRSZXfut"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"Mamatha\"   # A term that should be present in the inverted index\n",
        "QuerySearch(query1,invertedIndex)"
      ],
      "metadata": {
        "id": "VO4wXIwQShsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"ETRIAN\"   # A word term should not be present in the inverted index\n",
        "QuerySearch(query2,invertedIndex)"
      ],
      "metadata": {
        "id": "DSZFt_dbJnhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"Mamatha AND Devineni AND Ratnam\"  # A boolean AND query with each term in the inverted index\n",
        "QuerySearch(query3,invertedIndex)"
      ],
      "metadata": {
        "id": "_WCpjNw7KA9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query4 = \"Mamatha AND ETRIAN AND Ratnam\"  # A boolean AND query with at least one term that's not in the inverted index\n",
        "QuerySearch(query4,invertedIndex)"
      ],
      "metadata": {
        "id": "9b4SPfw7NfFO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}