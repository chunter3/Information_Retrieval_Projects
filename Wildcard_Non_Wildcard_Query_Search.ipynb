{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wildcard/Non-Wildcard Query Search",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzMIe01SfiU3iLRwlLcMhd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunter3/Information_Retrieval_Projects/blob/master/Wildcard_Non_Wildcard_Query_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FovtvFqM3P-z"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1 (start)"
      ],
      "metadata": {
        "id": "F-iUy4qINkrG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the state_union sample dataset from the nltk library\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('state_union')\n",
        "from nltk.corpus import state_union\n",
        "state_union.fileids()  # 65 documents w/in the state_union corpus"
      ],
      "metadata": {
        "id": "EztmciVm6OXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverted index function\n",
        "\n",
        "def InvertedIndex(corpus):\n",
        "  invertedIndex = {}\n",
        "  docID = 0\n",
        "  for textFile in corpus:\n",
        "    text = state_union.sents(textFile)\n",
        "    docID+=1\n",
        "    for sentence in text:   \n",
        "      joinTerms = ' '.join(sentence)        \n",
        "      processSent = (re.sub('[^A-Za-z0-9]+',' ', joinTerms)).split()\n",
        "      for word in processSent:\n",
        "         if word in invertedIndex and docID not in invertedIndex[word]:\n",
        "           invertedIndex[word].append(docID)\n",
        "      else:\n",
        "        invertedIndex[word] = [docID]\n",
        "  return invertedIndex"
      ],
      "metadata": {
        "id": "2Fy0qRlLYUlb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InvertedIndex(state_union.fileids())  # 3837 entries in the inverted index; 16097 tokens in total"
      ],
      "metadata": {
        "id": "mg1dHqZYhHbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1 (end)"
      ],
      "metadata": {
        "id": "i34jewi8jYyG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2 (start)"
      ],
      "metadata": {
        "id": "txgzoUZhjb37"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intersect auxilary function; called w/in primary function WCQSearch\n",
        "\n",
        "def Intersect(p1,p2):\n",
        "    intersect = [term for term in p1 if term in p2]\n",
        "    if intersect == []:\n",
        "      return p1\n",
        "    return intersect"
      ],
      "metadata": {
        "id": "VbX0mfpvfHEt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RelevantBigrams auxilary function; called w/in primary function WCQSearch\n",
        "\n",
        "def RelevantBigrams(bigrams,query):\n",
        "  relevantBigrams = []\n",
        "  partitionQuery = query.partition(\"*\")\n",
        "  for partition in partitionQuery:\n",
        "    if partition == \"*\" or \"\":\n",
        "      continue\n",
        "    for bigram in bigrams:\n",
        "      if len(bigram) == 1:\n",
        "        relevantBigrams.append(bigram)\n",
        "        continue\n",
        "      elif bigram in partition:\n",
        "        relevantBigrams.append(bigram)\n",
        "  return list(set(relevantBigrams))"
      ],
      "metadata": {
        "id": "Nd38dwPgruuI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wildcard query search function for single term wildcard queries\n",
        "\n",
        "def WCQSearch(query,index): \n",
        "  if \"*\" not in query or \" \" in query:                      # Return immediately if query isn't a wildcard\n",
        "    return \"Query is either not a wildcard or multi termed. Goodbye\"\n",
        "  finalDict = {}           # The final dictionary to be returned\n",
        "  bigramDict = {}          \n",
        "  bigrams = []\n",
        "  wcQuery = query          # The initial, untouched query; used during post-filtering phase\n",
        "\n",
        "#--------------------------------Bigram dictionary creation phase\n",
        "\n",
        "  if \"*\" == query[0]:\n",
        "    query = query.replace(\"*\",\"\") + \"$\"\n",
        "  elif \"*\" == query[-1]:\n",
        "    query = \"$\" + query.replace(\"*\",\"\")\n",
        "  else:\n",
        "    query = \"$\" + query.replace(\"*\",\"\") + \"$\" \n",
        "  for x in range (1,len(query)):\n",
        "      bigramDict[(query[x-1:x+1]).replace(\"$\",\"\")] = []     # Adds bigrams as keys to bigramDict\n",
        "      bigrams.append(query[x-1:x+1]) \n",
        "  for bigram in bigrams:\n",
        "    if \"$\" in bigram[0]:                                    # Handles bigrams where $ is in the front (e.g., \"$p\")\n",
        "      for key in index.keys():                             \n",
        "        if bigram[1] == key[0]:\n",
        "          bigramDict[bigram[1]].append(key)\n",
        "    elif \"$\" in bigram[1]:                                  # Handles bigrams where $ is in the back (e.g., \"p$\")\n",
        "      for key in index.keys():\n",
        "        if bigram[0] == key[-1]:\n",
        "          bigramDict[bigram[0]].append(key)\n",
        "    else:\n",
        "      for key in index.keys():                               # Handles bigrams w/out $s\n",
        "        if bigram in key:                 \n",
        "          bigramDict[bigram].append(key)\n",
        "  bigrams.clear()\n",
        "  for x in range (1,len(query)):                             # Creates new bigram list w/out $s\n",
        "    bigrams.append((query[x-1:x+1]).replace(\"$\",\"\"))\n",
        "  \n",
        "#--------------------------------Bigram dictionary created; post-filtering phase\n",
        "\n",
        "  relevantBigrams = RelevantBigrams(bigrams,wcQuery)          # Generates a list of the most significant bigrams based on query\n",
        "  partitionQuery = wcQuery.partition(\"*\")\n",
        "\n",
        "# ------------------------------------------------\n",
        "  if partitionQuery[2] == \"\" and wcQuery[-1:] == \"*\":\n",
        "    for key in index.keys():\n",
        "      if partitionQuery[0] == key[:len(partitionQuery[0])]:\n",
        "        finalDict[key] = index[key]                          \n",
        "    return finalDict\n",
        "                                                              # Handles terminal queries (e.g., *n or s*)\n",
        "  elif partitionQuery[0] == \"\" and wcQuery[0] == \"*\":\n",
        "    for key in index.keys():\n",
        "      if partitionQuery[2] == key[(-1 * (len(partitionQuery[2]))):]:\n",
        "        finalDict[key] = index[key]\n",
        "    return finalDict\n",
        "# --------------------------------------------------\n",
        "\n",
        "  intersect = []\n",
        "  intersect = Intersect(bigramDict[relevantBigrams[0]],bigramDict[relevantBigrams[1]])\n",
        "  del relevantBigrams[:2]\n",
        "  for bigram in relevantBigrams:\n",
        "      p1 = Intersect(intersect,bigramDict[bigram])\n",
        "      intersect = p1\n",
        "  if partitionQuery[0] == \"\" or partitionQuery[2] == \"\":                                 \n",
        "    for term in intersect:\n",
        "      finalDict[term] = index[term]\n",
        "  for term in intersect:\n",
        "        if partitionQuery[0] == term[:len(partitionQuery[0])] and partitionQuery[2] == term[(-1 * (len(partitionQuery[2]))):]:\n",
        "          finalDict[term] = index[term]\n",
        "  return finalDict"
      ],
      "metadata": {
        "id": "7Giy2a8Hlt5k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's examine a single term wildcard query to verify the function's accuracy\n",
        "wcQuery = \"un*y\" \n",
        "index = InvertedIndex(state_union.fileids())\n",
        "WCQSearch(wcQuery,index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1aRvIjFNhJU",
        "outputId": "ec23a054-bd85-44d8-f302-6948c0451ed7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'unanimity': [18],\n",
              " 'uncertainty': [59, 64, 65],\n",
              " 'underway': [41, 47],\n",
              " 'unduly': [32, 53],\n",
              " 'unevenly': [13],\n",
              " 'unity': [26, 28, 35, 36, 37, 41, 42, 43, 50, 60, 61, 62, 64],\n",
              " 'unnecessary': [36, 37, 38, 39, 53, 54, 55]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the following is returned for multi term or non-wildcard queries\n",
        "nwcQuery = \"Hello\"\n",
        "WCQSearch(nwcQuery,index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Fs7fd2lY2ru-",
        "outputId": "75540825-588b-460a-a3fb-b338b79c2f88"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Query is either not a wildcard or multi termed. Goodbye'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2 (end)"
      ],
      "metadata": {
        "id": "KKdGTDcPbduG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3 (start)"
      ],
      "metadata": {
        "id": "7yK7sk-jcEzk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-wildcard query search function for single term non-wildcard queries\n",
        "\n",
        "def NWCQSearch(query,index):\n",
        "  if \"*\" in query or \" \" in query:                      \n",
        "    return \"Query is either a wildcard or multi termed. Goodbye\"\n",
        "  finalDict = {}           \n",
        "  bigramDict = {}          \n",
        "  bigrams = []\n",
        "  for key in index.keys():\n",
        "    if query == key:              # If query is spelled correctly and in inverted index, return corresponding postings list\n",
        "      finalDict[key] = index[key]\n",
        "      return finalDict\n",
        "  nwcQuery = query        \n",
        "  if \"*\" == query[0]:\n",
        "    query = query.replace(\"*\",\"\") + \"$\"\n",
        "  elif \"*\" == query[-1]:\n",
        "    query = \"$\" + query.replace(\"*\",\"\")\n",
        "  else:\n",
        "    query = \"$\" + query.replace(\"*\",\"\") + \"$\" \n",
        "  for x in range (1,len(query)):\n",
        "      bigramDict[(query[x-1:x+1]).replace(\"$\",\"\")] = []     \n",
        "      bigrams.append(query[x-1:x+1]) \n",
        "  for bigram in bigrams:\n",
        "    if \"$\" in bigram[0]:                                   \n",
        "      for key in index.keys():                             \n",
        "        if bigram[1] == key[0]:\n",
        "          bigramDict[bigram[1]].append(key)\n",
        "    elif \"$\" in bigram[1]:                                  \n",
        "      for key in index.keys():\n",
        "        if bigram[0] == key[-1]:\n",
        "          bigramDict[bigram[0]].append(key)\n",
        "    else:\n",
        "      for key in index.keys():                              \n",
        "        if bigram in key:                 \n",
        "          bigramDict[bigram].append(key)\n",
        "  bigrams.clear()\n",
        "  for x in range (1,len(query)):                            \n",
        "    bigrams.append((query[x-1:x+1]).replace(\"$\",\"\"))\n",
        "\n",
        " #-------------------------------------Get edit distances        \n",
        "\n",
        "  editDists = []                    # 2D array of edit distances\n",
        "  minDists = []                     # 1D array of the minimum edit distances\n",
        "  for bigram in bigrams:\n",
        "    editDist = []                   # 1D array of edit distances\n",
        "    for term in bigramDict[bigram]:\n",
        "      editDist.append(nltk.edit_distance(nwcQuery,term))\n",
        "    editDists.append(editDist)\n",
        "  for lst in editDists:\n",
        "    minDists.append(min(lst))\n",
        "\n",
        "#------------------------------------Edit distances obtained; generating suggestions\n",
        "\n",
        "  minDist = min(minDists)\n",
        "  suggestions = []           # A list of potential spelling suggestions\n",
        "  pointer = -1                # Tracks list position in editDists\n",
        "  for lst in editDists:\n",
        "    pointer+=1\n",
        "    for x in range(0,len(lst)):\n",
        "      if lst[x] == minDist:\n",
        "        suggestions.append(bigramDict[bigrams[pointer]][x])\n",
        "  suggestions = list(set(suggestions))        # Removing duplicate suggestions\n",
        "  if len(suggestions) == 1:\n",
        "      return \"No search results. Did you mean '\" + suggestions[0] + \"'?\"\n",
        "  elif len(suggestions) == 2:\n",
        "      return \"No search results. Did you mean '\" + suggestions[0] + \"' or '\" + suggestions[1] + \"'?\"\n",
        "  else:\n",
        "      finalMsg = \"\"\n",
        "      for x in range(0,len(suggestions)):\n",
        "        if x == (len(suggestions) - 1):\n",
        "          finalMsg = finalMsg + \"or '\" + suggestions[x] + \"'?\"\n",
        "          break\n",
        "        finalMsg = \"'\" + suggestions[x] + \"', \" + finalMsg\n",
        "\n",
        "  return \"No search results. Did you mean \" + finalMsg"
      ],
      "metadata": {
        "id": "5vMDhy3aY9uT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test a correctly spelled single term non-wildcard query\n",
        "\n",
        "nwcquery = \"population\"\n",
        "NWCQSearch(nwcquery,index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaCzWANhZmR3",
        "outputId": "0a4f9cf2-cf8c-407f-f4c3-2d5ac4dacf8f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'population': [24, 25, 27, 28, 36, 40, 55, 62]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test a misspelled single term non-wildcard query\n",
        "\n",
        "nwcquery = \"cream\"\n",
        "NWCQSearch(nwcquery,index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GPmze9AGacLC",
        "outputId": "d7cd9757-7695-456f-fd00-3104fe9af563"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"No search results. Did you mean 'dream'?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Additionally, multiple suggestions are possible\n",
        "\n",
        "nwcquery = \"yost\"\n",
        "NWCQSearch(nwcquery,index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lW6LKj5DYhFx",
        "outputId": "f7780f94-208a-4b01-c451-dbefb4066b1d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"No search results. Did you mean 'cost', 'most', or 'lost'?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the following is returned for multi term or wildcard queries\n",
        "\n",
        "nwcquery = \"f*l\"\n",
        "NWCQSearch(nwcquery,index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dJT5WGWJY0O2",
        "outputId": "43eeeaf0-d322-4125-bfdd-779d8ead00ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Query is either a wildcard or multi termed. Goodbye'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3 (end)"
      ],
      "metadata": {
        "id": "er3H0shsZ6-x"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}